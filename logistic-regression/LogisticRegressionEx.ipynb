{
 "metadata": {
  "language": "lua",
  "name": "",
  "signature": "sha256:2d01a79f3707d1197e4ff853b57d664d6a942680e8b09917183fc5bf315a92b6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Logistic regression and multinomial logistic regression using Torch"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "require 'nn'\n",
      "require 'optim'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data come from a tutorial on using R from UCLA, which can be found at\n",
      "http://www.ats.ucla.edu/stat/r/dae/mlogit.htm\n",
      "\n",
      "The model is one of brand preference, where there are 3 brands and 2\n",
      "explanatory variables. \n",
      "\n",
      "The variables are coded this way:\n",
      "  + brand: 1, 2 or 3\n",
      "  + female: 1 if the person is a female, 0 if a male\n",
      "  + age: a positive integer\n",
      "\n",
      "The data are stored in a csv file 'example-logistic-regression.csv'\n",
      "and read with the csvigo package (torch-pkg install csvigo) or (luarocks install csvigo)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "require 'csvigo'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "true\t\n"
       ]
      }
     ],
     "prompt_number": 3
    },
        {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Create the training data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data are in a comma separated values (CSV) file. The first record\n",
      "contains field names and subsequent records contain data. The fields and\n",
      "their formats are:\n",
      " - num: observation number; an integer surrounded by double quote chars\n",
      " - brand: brand number; 1, 2, or 3 surrounded by double quote chars\n",
      " - female: indicator for is-female: 1 if female, 0 otherwise; no quote chars\n",
      " - age: age of the person; no quote characters\n",
      "\n",
      "Reading CSV files can be tricky. This code uses the csvigo package for this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loaded = csvigo.load('example-logistic-regression.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<csv>\tparsing file: example-logistic-regression.csv\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<csv>\ttidying up entries\t\n",
        "<csv>\treturning tidy table\t\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Convert the CSV table into dense tensors. The tensor form has the\n",
      "advantage that it stores its elements continguously (which leads to\n",
      "better performance) and a tensor allows one to select columns and rows\n",
      "easily, using slicing methods.\n",
      "\n",
      "First convert each variable list to a tensor:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brands = torch.Tensor(loaded.brand)\n",
      "females = torch.Tensor(loaded.female)\n",
      "ages = torch.Tensor(loaded.age)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Copy all the input variables into a single tensor:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset_inputs = torch.Tensor( (#brands)[1],2 )\n",
      "dataset_inputs[{ {},1 }] = females\n",
      "dataset_inputs[{ {},2 }] = ages"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The outputs are just the brands:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset_outputs = brands"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To implement the model, we need to know how many categories there are."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numberOfBrands = torch.max(dataset_outputs) - torch.min(dataset_outputs) + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Summarize the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function summarizeData()\n",
      "   function p(name,value) \n",
      "      print(string.format('%20s %f', name, value) )\n",
      "   end\n",
      "   p('number of brands', numberOfBrands)\n",
      "   p('min brand', torch.min(brands))\n",
      "   p('max brand', torch.max(brands))\n",
      "   \n",
      "   p('min female', torch.min(females))\n",
      "   p('max female', torch.max(females))\n",
      "   \n",
      "   p('min age', torch.min(ages))\n",
      "   p('max age', torch.max(ages))\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "summarizeData()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "    number of brands 3.000000\t\n",
        "           min brand 1.000000\t\n",
        "           max brand 3.000000\t\n",
        "          min female 0.000000\t\n",
        "          max female 1.000000\t\n",
        "             min age 24.000000\t\n",
        "             max age 38.000000\t\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Define the Model (Predictor)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The model is a multinomial logistic regression. \n",
      "\n",
      "It will consist of two layers that operate sequentially:\n",
      " - 1: a linear model\n",
      " - 2: a soft max layer\n",
      "\n",
      "The linear model supposes that the un-normalized probability of choosing\n",
      "a specific brand is proportional to the product of unknown weights and \n",
      "the observed variables plus a bias:\n",
      "\n",
      "Prob(brand = b) = bias + (weight1 \\* female \\* weight2 \\* age)\n",
      "  \n",
      "There are two inputs (female and age) and three outputs (one for each\n",
      "value that brand can take on)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "linLayer = nn.Linear(2,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The soft max layer takes the 3 outputs from the linear layer and\n",
      "transforms them to lie in the range (0,1) and to sum to 1. Thus, unlike\n",
      "some text books in which the probabilities are un-normalized, the output\n",
      "of the soft max layer will be normalized probabilities. \n",
      "\n",
      "The log soft max layer takes the log of these 3 outputs. This is done\n",
      "because we want to feed the log values into the ClassNLLCriterion\n",
      "described below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "softMaxLayer = nn.LogSoftMax()  -- the input and output are a single tensor"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need to put the layers into a sequential container."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = nn.Sequential()\n",
      "model:add(linLayer)\n",
      "model:add(softMaxLayer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. Define a loss function, to be minimized."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In that example, we minimize the cross entropy between\n",
      "the predictions of our linear model and the groundtruth available\n",
      "in the dataset.\n",
      "\n",
      "Torch provides many common criterions to train neural networks.\n",
      "\n",
      "The ClassNLLCriterion expects to be fed the log probabilities in a\n",
      "tensor. Hence, the use of the LogSoftMax layer in the model instead\n",
      "of SoftMax.\n",
      "\n",
      "Minimizing the cross-entropy is equivalent to maximizing the \n",
      "maximum a-posteriori (MAP) prediction, which is equivalent to \n",
      "minimizing the negative log-likelihoood (NLL), hence the use of\n",
      "the NLL loss."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "criterion = nn.ClassNLLCriterion()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4.a. Train the model (Using SGD)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To minimize the loss defined above, using the linear model defined\n",
      "in 'model', we follow a stochastic gradient descent procedure (SGD).\n",
      "\n",
      "SGD is a good optimization algorithm when the amount of training data\n",
      "is large, and estimating the gradient of the loss function over the \n",
      "entire training set is too costly.\n",
      "\n",
      "Given an arbitrarily complex model, we can retrieve its trainable\n",
      "parameters, and the gradients of our loss function wrt these \n",
      "parameters by doing so:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x, dl_dx = model:getParameters()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above statement does not create a copy of the parameters in the \n",
      "model! Instead it creates in x and dl_dx a view of the model's weights\n",
      "and derivative wrt the weights. The view is implemented so that when\n",
      "the weights and their derivatives changes, so do the x and dl_dx. The\n",
      "implementation is efficient in that the underlying storage is shared.\n",
      "\n",
      "A note on terminology: In the machine learning literature, the parameters\n",
      "that one seeks to learn are often called weights and denoted with a W.\n",
      "However, in the optimization literature, the parameter one seeks to \n",
      "optimize is often called x. Hence the use of x and dl_dx above.\n",
      "\n",
      "In the following code, we define a closure, feval, which computes\n",
      "the value of the loss function at a given point x, and the gradient of\n",
      "that function with respect to x. x is the vector of trainable weights,\n",
      "which, in this example, are all the weights of the linear matrix of\n",
      "our mode, plus one bias."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feval = function(x_new)\n",
      "   -- set x to x_new, if differnt\n",
      "   -- (in this simple example, x_new will typically always point to x,\n",
      "   -- so the copy is really useless)\n",
      "   if x ~= x_new then\n",
      "      x:copy(x_new)\n",
      "   end\n",
      "\n",
      "   -- select a new training sample\n",
      "   _nidx_ = (_nidx_ or 0) + 1\n",
      "   if _nidx_ > (#dataset_inputs)[1] then _nidx_ = 1 end\n",
      "\n",
      "   local inputs = dataset_inputs[_nidx_]\n",
      "   local target = dataset_outputs[_nidx_]\n",
      "\n",
      "   -- reset gradients (gradients are always accumulated, to accomodate \n",
      "   -- batch methods)\n",
      "   dl_dx:zero()\n",
      "\n",
      "   -- evaluate the loss function and its derivative wrt x, for that sample\n",
      "   local loss_x = criterion:forward(model:forward(inputs), target)\n",
      "   model:backward(inputs, criterion:backward(model.output, target))\n",
      "\n",
      "   -- return loss(x) and dloss/dx\n",
      "   return loss_x, dl_dx\n",
      "end\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given the function above, we can now easily train the model using SGD.\n",
      "For that, we need to define four key parameters:\n",
      "  + a learning rate: the size of the step taken at each stochastic \n",
      "    estimate of the gradient\n",
      "  + a weight decay, to regularize the solution (L2 regularization)\n",
      "  + a momentum term, to average steps over time\n",
      "  + a learning rate decay, to let the algorithm converge more precisely"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sgd_params = {\n",
      "   learningRate = 1e-3,\n",
      "   learningRateDecay = 1e-4,\n",
      "   weightDecay = 0,\n",
      "   momentum = 0\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're now good to go... all we have left to do is run over the dataset\n",
      "for a certain number of iterations, and perform a stochastic update \n",
      "at each iteration. The number of iterations is found empirically here,\n",
      "but should typically be determinined using cross-validation (i.e.\n",
      "using multiple folds of training/test subsets)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Epochs are number of times to cycle over our training data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epochs = 1e2 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Train with SGD"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i = 1,epochs do\n",
      "\n",
      "   -- this variable is used to estimate the average loss\n",
      "   current_loss = 0\n",
      "\n",
      "   -- an epoch is a full loop over our training data\n",
      "   for i = 1,(#dataset_inputs)[1] do\n",
      "\n",
      "      -- optim contains several optimization algorithms. \n",
      "      -- All of these algorithms assume the same parameters:\n",
      "      --   + a closure that computes the loss, and its gradient wrt to x, \n",
      "      --     given a point x\n",
      "      --   + a point x\n",
      "      --   + some parameters, which are algorithm-specific\n",
      "\n",
      "      _,fs = optim.sgd(feval,x,sgd_params)\n",
      "\n",
      "      -- Functions in optim all return two things:\n",
      "      --   + the new x, found by the optimization method (here SGD)\n",
      "      --   + the value of the loss functions at all points that were used by\n",
      "      --     the algorithm. SGD only estimates the function once, so\n",
      "      --     that list just contains one value.\n",
      "\n",
      "      current_loss = current_loss + fs[1]\n",
      "   end\n",
      "\n",
      "   -- report average error on epoch\n",
      "   current_loss = current_loss / (#dataset_inputs)[1]\n",
      "   print('epoch = ' .. i .. \n",
      "     ' of ' .. epochs .. \n",
      "     ' current loss = ' .. current_loss)\n",
      "\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 1 of 100 current loss = 1.2305139453196\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 2 of 100 current loss = 1.1638584885036\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 3 of 100 current loss = 1.1493459983691\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 4 of 100 current loss = 1.1368543224525\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 5 of 100 current loss = 1.1259974306795\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 6 of 100 current loss = 1.1164803620188\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 7 of 100 current loss = 1.1080743110872\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 8 of 100 current loss = 1.1005993214729\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 9 of 100 current loss = 1.0939120436343\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 10 of 100 current loss = 1.0878969565938\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 11 of 100 current loss = 1.0824599680491\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 12 of 100 current loss = 1.077523694145\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 13 of 100 current loss = 1.0730239245828\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 14 of 100 current loss = 1.068906945166\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 15 of 100 current loss = 1.0651274853427\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 16 of 100 current loss = 1.0616471272416\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 17 of 100 current loss = 1.0584330616905\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 18 of 100 current loss = 1.055457104092\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 19 of 100 current loss = 1.0526949104233\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 20 of 100 current loss = 1.0501253472434\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 21 of 100 current loss = 1.0477299809253\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 22 of 100 current loss = 1.0454926615351\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 23 of 100 current loss = 1.0433991813242\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 24 of 100 current loss = 1.0414369918254\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 25 of 100 current loss = 1.0395949690817\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 26 of 100 current loss = 1.0378632176081\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 27 of 100 current loss = 1.0362329055066\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 28 of 100 current loss = 1.0346961253877\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 29 of 100 current loss = 1.03324577701\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 30 of 100 current loss = 1.0318754661096\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 31 of 100 current loss = 1.0305794191189\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 32 of 100 current loss = 1.0293524094075\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 33 of 100 current loss = 1.0281896935918\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 34 of 100 current loss = 1.0270869567352\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 35 of 100 current loss = 1.0260402650026\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 36 of 100 current loss = 1.0250460239388\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 37 of 100 current loss = 1.0241009425324\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 38 of 100 current loss = 1.0232020016249\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 39 of 100 current loss = 1.0223464262204\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 40 of 100 current loss = 1.021531660758\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 41 of 100 current loss = 1.0207553480394\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 42 of 100 current loss = 1.0200153097896\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 43 of 100 current loss = 1.0193095298192\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 44 of 100 current loss = 1.0186361391301\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 45 of 100 current loss = 1.0179934027334\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 46 of 100 current loss = 1.0173797072983\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 47 of 100 current loss = 1.0167935507345\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 48 of 100 current loss = 1.0162335326266\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 49 of 100 current loss = 1.0156983457644\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 50 of 100 current loss = 1.0151867682976\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 51 of 100 current loss = 1.0146976565714\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 52 of 100 current loss = 1.0142299390798\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 53 of 100 current loss = 1.01378261085\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 54 of 100 current loss = 1.0133547282121\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 55 of 100 current loss = 1.0129454040777\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 56 of 100 current loss = 1.0125538037219\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 57 of 100 current loss = 1.0121791409767\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 58 of 100 current loss = 1.0118206746267\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 59 of 100 current loss = 1.0114777052721\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 60 of 100 current loss = 1.0111495723191\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 61 of 100 current loss = 1.010835651286\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 62 of 100 current loss = 1.0105353513917\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 63 of 100 current loss = 1.010248113238\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 64 of 100 current loss = 1.0099734067775\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 65 of 100 current loss = 1.0097107293446\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 66 of 100 current loss = 1.009459603913\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 67 of 100 current loss = 1.0092195774686\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 68 of 100 current loss = 1.0089902194835\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 69 of 100 current loss = 1.0087711205319\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 70 of 100 current loss = 1.0085618910224\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 71 of 100 current loss = 1.0083621600041\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 72 of 100 current loss = 1.0081715740318\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 73 of 100 current loss = 1.0079897961475\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 74 of 100 current loss = 1.0078165049418\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 75 of 100 current loss = 1.0076513936516\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 76 of 100 current loss = 1.0074941693346\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 77 of 100 current loss = 1.0073445521031\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 78 of 100 current loss = 1.0072022743946\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 79 of 100 current loss = 1.0070670802977\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 80 of 100 current loss = 1.0069387249379\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 81 of 100 current loss = 1.0068169738883\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 82 of 100 current loss = 1.0067016026106\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 83 of 100 current loss = 1.0065923959427\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 84 of 100 current loss = 1.0064891476494\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 85 of 100 current loss = 1.0063916598972\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 86 of 100 current loss = 1.0062997428671\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 87 of 100 current loss = 1.0062132143865\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 88 of 100 current loss = 1.0061318995123\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 89 of 100 current loss = 1.006055630205\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 90 of 100 current loss = 1.0059842449794\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 91 of 100 current loss = 1.0059175885752\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 92 of 100 current loss = 1.005855511711\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 93 of 100 current loss = 1.0057978707543\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 94 of 100 current loss = 1.0057445274649\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 95 of 100 current loss = 1.0056953487799\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 96 of 100 current loss = 1.0056502065629\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 97 of 100 current loss = 1.0056089773781\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 98 of 100 current loss = 1.0055715422886\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 99 of 100 current loss = 1.0055377866562\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "epoch = 100 of 100 current loss = 1.0055075999171\t\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4.b. Train the model (Using L-BFGS)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we know how to train the model using simple SGD, we can\n",
      "use more complex optimization heuristics. In the following, we\n",
      "use a second-order method: L-BFGS, which typically yields\n",
      "more accurate results (for linear models), but can be significantly\n",
      "slower. For very large datasets, SGD is typically much faster\n",
      "to converge, and L-FBGS can be used to refine the results.\n",
      "\n",
      "We start again, and reset the trained parameter vector:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model:reset()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we re-define the closure that evaluates f and df/dx, so that\n",
      "it estimates the true f, and true (exact) df/dx, over the entire\n",
      "dataset. This is a full batch approach."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feval = function(x_new)\n",
      "   -- set x to x_new, if differnt\n",
      "   -- (in this simple example, x_new will typically always point to x,\n",
      "   -- so the copy is really useless)\n",
      "   if x ~= x_new then\n",
      "      x:copy(x_new)\n",
      "   end\n",
      "\n",
      "   -- reset gradients (gradients are always accumulated, to accomodate \n",
      "   -- batch methods)\n",
      "   dl_dx:zero()\n",
      "\n",
      "   -- and batch over the whole training dataset:\n",
      "   local loss_x = 0\n",
      "   for i = 1,(#dataset_inputs)[1] do\n",
      "      -- select a new training sample\n",
      "      _nidx_ = (_nidx_ or 0) + 1\n",
      "      if _nidx_ > (#dataset_inputs)[1] then _nidx_ = 1 end\n",
      "\n",
      "      local inputs = dataset_inputs[_nidx_]\n",
      "      local target = dataset_outputs[_nidx_]\n",
      "\n",
      "      -- evaluate the loss function and its derivative wrt x, for that sample\n",
      "      loss_x = loss_x + criterion:forward(model:forward(inputs), target)\n",
      "      model:backward(inputs, criterion:backward(model.output, target))\n",
      "   end\n",
      "\n",
      "   -- normalize with batch size\n",
      "   loss_x = loss_x / (#dataset_inputs)[1]\n",
      "   dl_dx = dl_dx:div( (#dataset_inputs)[1] )\n",
      "\n",
      "   -- return loss(x) and dloss/dx\n",
      "   return loss_x, dl_dx\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "L-BFGS parameters are different than SGD:\n",
      "  + a line search: we provide a line search, which aims at finding the point that minimizes the loss locally\n",
      "  + max nb of iterations: the maximum number of iterations for the batch,\n",
      "   which is equivalent to the number of epochs\n",
      "   on the given batch. In that example, it's simple\n",
      "   because the batch is the full dataset, but in\n",
      "   some cases, the batch can be a small subset\n",
      "   of the full dataset, in which case maxIter\n",
      "   becomes a more subtle parameter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lbfgs_params = {\n",
      "   lineSearch = optim.lswolfe,\n",
      "   maxIter = epochs,\n",
      "   verbose = true\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training with L-BFGS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_,fs = optim.lbfgs(feval,x,lbfgs_params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "<optim.lbfgs> \tstep size below tolX\t\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "fs contains all the evaluations of f, during optimization\n",
      "\n",
      "history of L-BFGS evaluations:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(fs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "{\n",
        "  1 : 8.7712787030945\n",
        "  2 : 8.4144744805239\n",
        "  3 : 4.1012994477108\n",
        "  4 : 1.849832318174\n",
        "  5 : 1.0985587788091\n",
        "  6 : 1.087547215441\n",
        "  7 : 1.082985797527\n",
        "  8 : 1.0826264507609\n",
        "  9 : 1.0826216754154\n",
        "  10 : 1.0826036967998\n",
        "  11 : 1.0825596295787\n",
        "  12 : 1.0824424579304\n",
        "  13 : 1.0821454171302\n",
        "  14 : 1.0814087677024\n",
        "  15 : 1.0797393691864\n",
        "  16 : 1.0766395984703\n",
        "  17 : 1.0729071342928\n",
        "  18 : 1.0707490794703\n",
        "  19 : 1.0702367711472\n",
        "  20 : 1.0701954480403\n",
        "  21 : 1.0701917326396\n",
        "  22 : 1.0701547496575\n",
        "  23 : 1.0697796313229\n",
        "  24 : 1.0690902091562\n",
        "  25 : 1.067049222403\n",
        "  26 : 1.0623023392901\n",
        "  27 : 1.0514929263448\n",
        "  28 : 1.0322170140304\n",
        "  29 : 1.0092677566496\n",
        "  30 : 0.99657003731644\n",
        "  31 : 0.99336834069594\n",
        "  32 : 0.99227542857616\n",
        "  33 : 0.99118340804434\n",
        "  34 : 0.98857160104473\n",
        "  35 : 0.98259849050906\n",
        "  36 : 0.97247092246564\n",
        "  37 : 0.96215678178337\n",
        "  38 : 0.95845482241794\n",
        "  39 : 0.95793225152577\n",
        "  40 : 0.95791252287831\n",
        "  41 : 0.95791222441926\n",
        "  42 : 0.95791211684312\n",
        "  43 : 0.95791189587652\n",
        "  44 : 0.95791135731385\n",
        "  45 : 0.95790997386286\n",
        "  46 : 0.95790638511496\n",
        "  47 : 0.95789706054851\n",
        "  48 : 0.95787300818212\n",
        "  49 : 0.95781230555255\n",
        "  50 : 0.95766776381096\n",
        "  51 : 0.95736938820436\n",
        "  52 : 0.95692037065531\n",
        "  53 : 0.95654327285258\n",
        "  54 : 0.95643555237499\n",
        "  55 : 0.9564262286139\n",
        "  56 : 0.95642586648797\n",
        "  57 : 0.95642585675421\n",
        "  58 : 0.9564258553691\n",
        "  59 : 0.9564258553691\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5. Test the trained model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the model is trained, one can test it by evaluating it\n",
      "on new samples.\n",
      "\n",
      "The model constructed and trained above computes the probabilities\n",
      "of each class given the input values.\n",
      "\n",
      "We want to compare our model's results with those from the text.\n",
      "The input variables have narrow ranges, so we just compare all possible\n",
      "input variables in the training data.\n",
      "\n",
      "Determine actual frequency of the each female-age pair in the \n",
      "training data\n",
      "\n",
      "Return index of largest value:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function maxIndex(a,b,c)\n",
      "   if a >=b and a >= c then return 1 \n",
      "   elseif b >= a and b >= c then return 2\n",
      "   else return 3 end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Return predicted brand and probabilities of each brand\n",
      "for the model in the text\n",
      "\n",
      "The R code in the text computes the probabilities of choosing\n",
      "brands 2 and 3 relative to the probability of choosing brand 1:\n",
      " +   Prob(brand=2)/prob(brand=1) = exp(-11.77 + 0.52\\*female + 0.37\\*age)\n",
      " +   Prob(brand=3)/prob(brand=1) = exp(-22.72 + 0.47\\*female + 0.69\\*age)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function predictText(age, female)\n",
      "   --   1: calculate the \"logit's\"\n",
      "   --      The coefficients come from the text.\n",
      "   --      If you download the R script and run it, you may see slightly\n",
      "   --      different results.\n",
      "   local logit1 = 0\n",
      "   local logit2 = -11.774655 + 0.523814 * female + 0.368206 * age\n",
      "   local logit3 = -22.721396 + 0.465941 * female + 0.685908 * age\n",
      "\n",
      "   --   2: calculate the unnormalized probabilities\n",
      "   local uprob1 = math.exp(logit1)\n",
      "   local uprob2 = math.exp(logit2)\n",
      "   local uprob3 = math.exp(logit3)\n",
      "\n",
      "   --   3: normalize the probabilities\n",
      "   local z = uprob1 + uprob2 + uprob3\n",
      "   local prob1 = (1/z) * uprob1\n",
      "   local prob2 = (1/z) * uprob2\n",
      "   local prob3 = (1/z) * uprob3\n",
      "\n",
      "   return maxIndex(prob1, prob2, prob3), prob1, prob2, prob3\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Return predicted brand and the probabilities of each brand\n",
      "for our model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function predictOur(age, female)\n",
      "   local input = torch.Tensor(2)\n",
      "   input[1] = female  -- must be in same order as when the model was trained!\n",
      "   input[2] = age\n",
      "   local logProbs = model:forward(input)  \n",
      "   --print('predictOur', age, female, input)\n",
      "   local probs = torch.exp(logProbs)\n",
      "   --print('logProbs', logProbs)\n",
      "   --print('probs', probs[1], probs[2], probs[3] )\n",
      "   local prob1, prob2, prob3 = probs[1], probs[2], probs[3]\n",
      "   return maxIndex(prob1, prob2, prob3), prob1, prob2, prob3\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function makeKey(age, brand, female)\n",
      "   -- return a string containing the values\n",
      "\n",
      "   -- Note that returning a table will not work, because each\n",
      "   -- table is unique.\n",
      "\n",
      "   -- Because Lua interns the strings, a string with a given sequence\n",
      "   -- of characters is stored only once.\n",
      "   return string.format('%2d%1d%1f', age, brand, female)\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i = 1,(#brands)[1] do\n",
      "   local brand = brands[i]\n",
      "   local female = females[i]\n",
      "   local age = ages[i]\n",
      "   local key = makeKey (age, brand, female)\n",
      "   counts[key] = (counts[key] or 0) + 1\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Return probability of each brand conditioned on age and female"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function actualProbabilities(age, female)\n",
      "   function countOf(age, brand, female)\n",
      "      return counts[makeKey(age, brand, female)] or 0\n",
      "   end\n",
      "   local count1 = countOf(age, 1, female)\n",
      "   local count2 = countOf(age, 2, female)\n",
      "   local count3 = countOf(age, 3, female)\n",
      "   local sumCounts = count1 + count2 + count3\n",
      "   if sumCounts == 0 then\n",
      "      return 0, 0, 0\n",
      "   else\n",
      "      return count1/sumCounts, count2/sumCounts, count3/sumCounts\n",
      "   end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Summary of Data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "summarizeData()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "    number of brands 3.000000\t\n",
        "           min brand 1.000000\t\n",
        "           max brand 3.000000\t\n",
        "          min female 0.000000\t\n",
        "          max female 1.000000\t\n",
        "             min age 24.000000\t\n",
        "             max age 38.000000\t\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Training variables:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k,v in pairs(sgd_params) do\n",
      "   print(string.format('%20s %f', k, v))\n",
      "end\n",
      "print(string.format('%20s %f', 'epochs', epochs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "         evalCounter 73500.000000\t\n",
        "   learningRateDecay 0.000100\t\n",
        "        learningRate 0.001000\t\n",
        "         weightDecay 0.000000\t\n",
        "            momentum 0.000000\t\n",
        "              epochs 100.000000\t\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('current loss', current_loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "current loss\t1.0055075999171\t\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Print the headers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lineFormat = '%-6s %-3s| %-17s | %-17s | %-17s | %-1s %-1s %-1s'\n",
      "print(\n",
      "   string.format(lineFormat,\n",
      "\t\t '', '', \n",
      "\t\t 'actual probs', 'text probs', 'our probs', \n",
      "\t\t 'best', '', ''))\n",
      "choices = 'brnd1 brnd2 brnd3'\n",
      "print(string.format(lineFormat,\n",
      "\t\t    'female', 'age', \n",
      "\t\t    choices, choices, choices, \n",
      "\t\t    'a', 't', 'o'))\n",
      "-- print each row in the table\n",
      "\n",
      "function formatFemale(female)\n",
      "   return string.format('%1d', female)\n",
      "end\n",
      "\n",
      "function formatAge(age)\n",
      "   return string.format('%2d', age)\n",
      "end\n",
      "\n",
      "function formatProbs(p1, p2, p3)\n",
      "   return string.format('%5.3f %5.3f %5.3f', p1, p2, p3)\n",
      "end\n",
      "\n",
      "function indexString(p1, p2, p3)\n",
      "   -- return index of highest probability or '-' if nearly all zeroes\n",
      "   if p1 < 0.001 and p2 < 0.001 and p3 < 0.001 then\n",
      "      return '-'\n",
      "   else \n",
      "      return string.format('%1d', maxIndex(p1, p2, p3))\n",
      "   end\n",
      "end\n",
      "\n",
      "-- print table rows and accumulate accuracy\n",
      "for female = 0,1 do\n",
      "   for age = torch.min(ages),torch.max(ages) do\n",
      "      -- calculate the actual probabilities in the training data\n",
      "      local actual1, actual2, actual3 = actualProbabilities(age, female)\n",
      "      -- calculate the prediction and probabilities using the model in the text\n",
      "      local textBrand, textProb1, textProb2, textProb3 = \n",
      "\t predictText(age, female)\n",
      "      -- calculate the probabilities using the model we just trained\n",
      "      --print(\"main\", age, female)\n",
      "      local ourBrand, ourProb1, ourProb2, ourProb3 = \n",
      "\t predictOur(age, female)\n",
      "      print(\n",
      "\t string.format(lineFormat,\n",
      "\t\t       formatFemale(female), \n",
      "\t\t       formatAge(age),\n",
      "\t\t       formatProbs(actual1, actual2, actual3),\n",
      "\t\t       formatProbs(textProb1, textProb2, textProb3),\n",
      "\t\t       formatProbs(ourProb1, ourProb2, ourProb3),\n",
      "\t\t       indexString(actual1,actual2,actual3),\n",
      "\t\t       indexString(textProb1,textProb2,textProb3),\n",
      "\t\t       indexString(ourProb1,ourProb2,ourProb3))\n",
      "\t   )\n",
      "   end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "          | actual probs      | text probs        | our probs         | best    \t\n",
        "female age| brnd1 brnd2 brnd3 | brnd1 brnd2 brnd3 | brnd1 brnd2 brnd3 | a t o\t\n",
        "0      24 | 1.000 0.000 0.000 | 0.948 0.050 0.002 | 0.948 0.050 0.002 | 1 1 1\t\n",
        "0      25 | 0.000 0.000 0.000 | 0.926 0.071 0.004 | 0.926 0.071 0.004 | - 1 1\t\n",
        "0      26 | 1.000 0.000 0.000 | 0.894 0.099 0.007 | 0.894 0.099 0.007 | 1 1 1\t\n",
        "0      27 | 1.000 0.000 0.000 | 0.851 0.136 0.013 | 0.851 0.136 0.013 | 1 1 1\t\n",
        "0      28 | 0.667 0.000 0.333 | 0.793 0.183 0.024 | 0.793 0.183 0.024 | 1 1 1\t\n",
        "0      29 | 0.875 0.125 0.000 | 0.718 0.240 0.042 | 0.718 0.240 0.042 | 1 1 1\t\n",
        "0      30 | 0.500 0.333 0.167 | 0.625 0.302 0.073 | 0.625 0.302 0.073 | 1 1 1\t\n",
        "0      31 | 0.588 0.294 0.118 | 0.518 0.361 0.121 | 0.518 0.361 0.121 | 1 1 1\t\n",
        "0      32 | 0.407 0.432 0.161 | 0.405 0.408 0.187 | 0.405 0.408 0.187 | 2 2 2\t\n",
        "0      33 | 0.211 0.474 0.316 | 0.296 0.432 0.272 | 0.296 0.432 0.272 | 2 2 2\t\n",
        "0      34 | 0.167 0.542 0.292 | 0.203 0.427 0.370 | 0.203 0.427 0.370 | 2 2 2\t\n",
        "0      35 | 0.000 0.182 0.818 | 0.131 0.397 0.472 | 0.131 0.397 0.472 | 3 3 3\t\n",
        "0      36 | 0.133 0.333 0.533 | 0.080 0.350 0.571 | 0.080 0.350 0.571 | 3 3 3\t\n",
        "0      37 | 0.200 0.200 0.600 | 0.046 0.294 0.660 | 0.046 0.294 0.660 | 3 3 3\t\n",
        "0      38 | 0.000 0.278 0.722 | 0.026 0.239 0.735 | 0.026 0.239 0.735 | 3 3 3\t\n",
        "1      24 | 0.000 0.000 0.000 | 0.915 0.082 0.003 | 0.915 0.082 0.003 | - 1 1\t\n",
        "1      25 | 0.000 0.000 0.000 | 0.881 0.114 0.005 | 0.881 0.114 0.005 | - 1 1\t\n",
        "1      26 | 0.000 0.000 0.000 | 0.834 0.156 0.010 | 0.834 0.156 0.010 | - 1 1\t\n",
        "1      27 | 0.800 0.000 0.200 | 0.773 0.209 0.018 | 0.773 0.209 0.018 | 1 1 1\t\n",
        "1      28 | 0.667 0.222 0.111 | 0.696 0.271 0.033 | 0.696 0.271 0.033 | 1 1 1\t\n",
        "1      29 | 0.636 0.364 0.000 | 0.603 0.340 0.057 | 0.603 0.340 0.057 | 1 1 1\t\n",
        "1      30 | 0.588 0.235 0.176 | 0.500 0.407 0.093 | 0.500 0.407 0.093 | 1 1 1\t\n",
        "1      31 | 0.391 0.391 0.217 | 0.392 0.462 0.145 | 0.392 0.462 0.145 | 1 2 2\t\n",
        "1      32 | 0.288 0.544 0.167 | 0.291 0.495 0.214 | 0.291 0.495 0.214 | 2 2 2\t\n",
        "1      33 | 0.083 0.639 0.278 | 0.203 0.500 0.297 | 0.203 0.500 0.297 | 2 2 2\t\n",
        "1      34 | 0.150 0.400 0.450 | 0.134 0.477 0.389 | 0.134 0.477 0.389 | 3 2 2\t\n",
        "1      35 | 0.042 0.250 0.708 | 0.084 0.432 0.484 | 0.084 0.432 0.484 | 3 3 3\t\n",
        "1      36 | 0.109 0.345 0.545 | 0.050 0.374 0.576 | 0.050 0.374 0.576 | 3 3 3\t\n",
        "1      37 | 0.000 0.294 0.706 | 0.029 0.311 0.660 | 0.029 0.311 0.659 | 3 3 3\t\n",
        "1      38 | 0.071 0.214 0.714 | 0.016 0.252 0.732 | 0.016 0.252 0.732 | 3 3 3\t\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
